\documentclass[
  ngerman,
  DIV=14
]{scrartcl}
\usepackage{babel}
\usepackage{csquotes}

% typography
\usepackage{fontspec}
%\usepackage[utopia]{mathdesign}
\usepackage{newpxmath}
\setsansfont{Open Sans}[
  BoldFont={Open Sans Bold},
  ItalicFont={Open Sans Italic}]
\setmonofont[Scale=0.87]{Menlo}
\setmainfont{Palatino}
\linespread{1.15}
%\renewcommand\familydefault{\sfdefault}
\usepackage[factor=1000]{microtype}

% graphics, drawings, etc.
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{soul}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{shapes.arrows}
\usetikzlibrary{positioning}

% highlighting, lists, code
\usepackage{listings}
\lstset{
  basicstyle=\ttfamily,
  numberstyle=\sffamily\footnotesize\color{gray},
  %escapeinside=||,
  keywordstyle=\color{blue!50!black},
  stringstyle=\color{green!50!black}}

% math
\usepackage{amsmath}
\usepackage{siunitx}

% links
\usepackage[
  colorlinks,
  linkcolor={red!50!black},
  citecolor={blue!50!black},
  urlcolor={blue!80!black}
]{hyperref}

\subject{Visual Computing}
\title{Objekterkennung und Bayes}
\subtitle{Übungsblatt 3}
\author{Patrick Elsen, Dmytro Klepatskyi,\\Costa Weiland, Nana Atchoukeu Chris-Mozart}
\date{Wintersemester 2018-2019}
\publishers{Technische Universität Darmstadt}

\begin{document}
\maketitle

\section*{Aufgabe 1: Gesichtserkennung}

\emph{Benennen Sie das im folgenden Bild dargestellte Verfahren und erklären Sie kurz, wie dieses funktioniert.}

Das auf dem Bild dargestellte Verfahren heißt \emph{Sliding Window Approach} (Suchen über Raum und Skalierung). Das Verfahren gehört zu den \emph{Appearance-Based Methoden}. Das Bild wird zunächst horizontal und vertikal gescannt. Dann wird das Bild um 1,2 verkleinert und wieder gescannt. Dies wird wiederholt, bis das Bild zu klein ist.

\bigskip\noindent
\emph{Wie setzen sich die Trainingsdaten für dieses Verfahren zusammen?}

Die Trainingsdaten setzen sich aus sowohl negativen (keine Gesichter) als auch positiven Beispielen (Gesichter). Durch diese Datensammlung ist für das Lernen des Erscheinungsmodells relevant.

\section*{Aufgabe 2: Bayes Decision Theory}

\emph{Was sagen prior $P(C_k)$, likelihood $P(x|C_k)$ und posteriori $P(C_k|x)$ aus? Hinweis: $C_k$ ist eine Klasse und $x$ ein Merkmal.}

Die \emph{a priori} oder prior Wahrscheinlichkeit sagt aus, mit welcher Wahrscheinlichkeit wir eine gewisse Klasse erwarten, ohne dass wir irgendwelche weiteren Informationen haben. Wenn man von der Buchstabenerkennung von deutschem Test ausgeht, dan kann man mit einem kleinen Ruby-Programm die relativen Wahrscheinlichkeiten der Buchstaben im Deutschen ermitteln. 
\begin{lstlisting}[language=ruby,numbers=left]
def sorted_distribution(text)
  absolute_distribution = text
    .scan(/[a-zA-Z]/)
    .inject({}){|m,c| m[c] = (m[c]||0)+1; m}
  total = absolute_distribution.values.sum
  relative_distribution = absolute_distribution
    .map{|k, v| [k, v.to_f / total]}
  sorted = relative_distribution
    .sort_by{|k, v| v}
end

# https://raw.githubusercontent.com/martinth/mobverdb/master/faust.txt
faust_distribution = sorted_distribution(File.read("faust.txt"))
puts "Faust: P(C_#{faust_distribution.last[0]}) = #{faust_distribution.last[1]}"
\end{lstlisting}
Dieses Programm gibt aus $P(C_e) = 0,14328213937810988$. Das bedeutet also, wenn wir deutsche Buchstaben erkennen wollen, und wir nichts weiter über den Buchstaben wissen, dann wissen wir, dass der Buchstabe mit einer Wahrscheinlichkeit von 14,3\% ein kleines \emph{e} sein könnte.

Wenn wir genauer über Buchstaben urteilen wollen, dann müssen wir uns Merkmale anschauen und messen. Das können zum Beispiel Dimensionen, Pixelwerte oder ähnliches sein. $P(x|C_k)$ ist die Wahrscheinlichkeit, dass ein Buchstabe der Klasse $C_k$ das Merkmal $x$ besitzt. Das kann man lesen als \emph{die Wahrscheinlichkeit von $x$ wenn $C_k$ gegeben ist}. Dies nennt man auch \emph{likelihood}.

Fast das Gegenteil dazu ist die \emph{posteriori}-Wahrscheinlichkeit. Hat man einen unbekannten Buchstaben, bei dem man das Merkmal $x$ gemessen hat, dann sagt einem $P(C_k|x)$ wie groß die Wahrscheinlichkeit ist, dass es sich hierbei um einen Buchstaben der Klasse $C_k$ handelt.

\bigskip\noindent
\emph{Gegeben sei der Satz \enquote{Der Satz von Bayes ist nach dem englischen Statistiker Thomas Bayes benannt.} Bestimmen Sie die Prior-Wahrscheinlichkeit des Buchstaben \enquote{s} im zuvor zitierten Satz. Hinweis: Nur Buchstaben werden als relevante Zeichen für die Prior-Wahrscheinlichkeit betrachtet. Kommas, Punkte, Leerzeichen, etc. werden ignoriert.}

Hier können wir wieder das Ruby-Programm verwenden. Dazu führen wir die Funktion einfach auf dem gegebenen Text aus.
\begin{lstlisting}[language=ruby,numbers=left]
quote = "Der Satz von Bayes ist nach dem englischen Statistiker Thomas Bayes benannt."
quote_distribution = sorted_distribution(quote)
puts "Quote: P(C_s) = #{quote_distribution.to_h['s']}"
\end{lstlisting}
Dabei bekommen wir den Output $P(s) = 0,09375$.

\medskip\noindent
\emph{Zusätzlich ist $P(x|s) = 0,4$ und $P(x) = 0,1$ gegeben, wobei $x$ ein beliebiges Merkmal ist. Berechnen Sie die a-posteriori-Wahrscheinlichkeit $P(s|x)$.}

Hier kann man einfach eine Formel anwenden.
\begin{equation*}
P(s|x) = \frac{P(x|s)P(s)}{P(x)} = \frac{0,4 \cdot 0,09375}{0,1} = 0,00375
\end{equation*}

\medskip\noindent
\emph{Wie groß ist die Summe der Prior-Wahrscheinlichkeiten für alle relevanten Zeichen im oben zitierten Satz?}

Per Definition ist die Summe aller Zeichen 1. 

\medskip\noindent
\emph{Was nimmt der Naive Bayes Klassifikator an? Trifft diese Annahme immer zu?}

Der naïve Bayes-Klassifikator nimmt an, dass alle Merkmale $x_0, \dots, x_n$ statistisch unabhängig sind. Das ist nicht immer wahr, gibt aber in der Praxis gute Resultate.

\section*{Aufgabe 3: Erkennungsarten}

\emph{Wie unterscheiden sich die Begriffe \emph{Identifikation} und \emph{Verifikation} voneinander?}

Bei der Verifikation gibt die Person ihre Identifikationsdaten (Benutzer-ID, E-Mail) dem System, und das System verifiziert anhand der biometrischen Merkmale ob die Person tatsächlich präsent ist. 

Bei einer Identifikation findet das System allein anhand der biometrischen Merkmale heraus, um welche Person es sich handelt, und verifiziert diese. Das System muss die biometrischen Daten also mit denen aller Benutzer in den Referenzmerkmalsdatensätzen abgleichen.

\bigskip\noindent
\emph{Geben Sie für jede Erkennungsart einen Anwendungsfall an.}

Der Irisscanner an der Arbeitsstelle ist ein Verifikationssystem. Hier präsentiert man seinen Arbeitsausweis, der dem System per RFID mitteilt um welche Person es sich handelt. Der Irisabgleich ist also nur dazu da, um sicherzustellen, dass es sich wirklich um die richtige Person handelt, bevor man sicherheitskritische Bereiche betreten kann.

Die Gesichtserkennung, die von der chinesischen Regierung benutzt wird, um als Teil des \emph{Social Credit}-Programms die Aktionen der Bürger zu überwachen\footnote{\url{https://www.scmp.com/node/2157883}}, ist ein Beispiel für ein Identifikationssystem. Hierbei werden aufgezeichnete Gesichter in Echtzeit mit einer Genaugkeit von 90\% mit einer 1,2 Milliarden großen Datenbank verglichen, um die Menschen zu identifizieren und negative Aktionen zu bestrafen. Beispielsweise können Punkte abgezogen werden, wenn man bei Rot über die Ampel geht. 

\end{document}